{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import json\n",
    "# import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from aiohttp import ClientSession\n",
    "import datetime\n",
    "import matplotlib\n",
    "import os\n",
    "from functools import partial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 16,
>>>>>>> a38ba4bce0beba180837027c10d9d4ffa096e908
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_mapping = pd.Series.from_csv('../label_names.csv',header=0).to_dict()\n",
    "labels = pd.read_csv(\"../train_labels.csv\", header=None)\n",
    "labels.columns = [\"videoId\", \"labels\"]\n",
    "\n",
    "API_KEY = \"AIzaSyAASvUHmmE-OltIz1_nb8NGdEQrVHjWNTA\"\n",
    "\n",
    "async def extract_video_info(video_id, session):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/videos?part=snippet,contentDetails,statistics&id={0}&key={1}\"\\\n",
    "        .format(video_id, API_KEY)\n",
    "    res = await session.get(url)\n",
    "#     meta = json.loads(res.text)\n",
    "    meta = await res.json()\n",
    "#     res.close()\n",
    "    try:\n",
    "        items = meta['items'][0]\n",
    "    except IndexError:\n",
    "        return None\n",
    "    except KeyError:\n",
    "        return None\n",
    "    try:\n",
    "        duration = items['contentDetails']['duration']\n",
    "        title = items['snippet']['title']\n",
    "        channel_id = items['snippet']['channelId']\n",
    "        channel_title = items['snippet']['channelTitle']\n",
    "        published_at = items['snippet']['publishedAt']\n",
    "        views = items['statistics']['viewCount']\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        likes = items['statistics']['likeCount']\n",
    "        dislikes = items['statistics']['dislikeCount']\n",
    "    except KeyError:\n",
    "        likes = -999  # missing value\n",
    "        dislikes = -999\n",
    "    try:\n",
    "        comments = items['statistics']['commentCount']\n",
    "    except KeyError:\n",
    "        comments = -999\n",
    "    return [video_id, duration, title, channel_id, channel_title, published_at, views, likes, dislikes, comments]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 4,
>>>>>>> a38ba4bce0beba180837027c10d9d4ffa096e908
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4906660, 2)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 3,
=======
     "execution_count": 4,
>>>>>>> a38ba4bce0beba180837027c10d9d4ffa096e908
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 20,
>>>>>>> a38ba4bce0beba180837027c10d9d4ffa096e908
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "loading data from 500000 to 501000\n",
      "loading data from 501000 to 502000\n",
      "loading data from 502000 to 503000\n",
      "loading data from 503000 to 504000\n",
      "loading data from 504000 to 505000\n",
      "loading data from 505000 to 506000\n",
      "loading data from 506000 to 507000\n",
      "loading data from 507000 to 508000\n",
      "loading data from 508000 to 509000\n",
      "loading data from 509000 to 510000\n",
      "loading data from 510000 to 511000\n",
      "loading data from 511000 to 512000\n",
      "loading data from 512000 to 513000\n",
      "loading data from 513000 to 514000\n",
      "loading data from 514000 to 515000\n"
=======
      "loading data from 490000 to 491000\n",
      "loading data from 491000 to 492000\n",
      "loading data from 492000 to 493000\n",
      "loading data from 493000 to 494000\n",
      "loading data from 494000 to 495000\n",
      "loading data from 495000 to 496000\n",
      "loading data from 496000 to 497000\n",
      "loading data from 497000 to 498000\n",
      "loading data from 498000 to 499000\n",
      "loading data from 499000 to 500000\n"
>>>>>>> a38ba4bce0beba180837027c10d9d4ffa096e908
     ]
    }
   ],
   "source": [
    "# extract info for a few videos\n",
<<<<<<< HEAD
    "start = 600000\n",
    "end = 700000\n",
=======
    "start = 500000\n",
    "end = 600000\n",
>>>>>>> a38ba4bce0beba180837027c10d9d4ffa096e908
    "step = 1000\n",
    "\n",
    "async def gather_results(curr, step):\n",
    "    tasks = []\n",
    "    async with ClientSession() as session:\n",
    "        for video_id in labels['videoId'][curr : curr + step]:\n",
    "            task = asyncio.ensure_future(extract_video_info(video_id, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        # you now have all response bodies in this variable\n",
    "        return responses\n",
    "\n",
    "def process_df(future, curr, step):\n",
    "    cache = [r for r in future.result() if r is not None]\n",
    "    df = pd.DataFrame(cache, columns=['video_id', 'duration', 'title', 'channel_id', \n",
    "                   'channel_title', 'published_at', 'views', 'likes', 'dislikes', 'comments'])\n",
    "    df['views'] = df['views'].astype(int)\n",
    "    df['likes'] = df['likes'].astype(int)\n",
    "    df['dislikes'] = df['dislikes'].astype(int)\n",
    "    df['comments'] = df['comments'].astype(int)\n",
    "    df['published_at'] = df['published_at'].apply(lambda t: datetime.datetime.strptime(t, '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "    try:\n",
    "        os.mkdir('meta/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    df.to_csv('meta/meta_{0}_{1}.csv'.format(curr, curr + step))\n",
    "    \n",
    "for curr in range(start, end, step):\n",
    "    print(\"loading data from {0} to {1}\".format(curr, curr + step))\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(gather_results(curr, step))\n",
    "    future.add_done_callback(partial(process_df, curr=curr, step=step))\n",
    "    loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
